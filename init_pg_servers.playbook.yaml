---
- name: Global vars and naming conventions
  hosts: postgres, aws_commands_host
  gather_facts: false
  remote_user: root
  vars:
    credentials_store: /tmp # please provide some folder and store it's content in a secure place
    recover_from: None # folder with a full backup + transaction logs, e.g. s3://backup--test-postgres.prod.my-organization.com/2017-03-22_10-28-53.971751329/
    recovery_target_time: '' # provide value for point in time recovery, e.g. '2017-03-22 15:50:12'
  tasks:
    - debug: var=hostvars[inventory_hostname]["group_names"]
    - set_fact: # remove DC dependent part, e.g. 10preprod0000 -> preprod0000
        cred_zone: "{{ zone | regex_replace('^\\d+', '') }}"
    - set_fact:
        backup_bucket_name:  "backup--{{ postgres_service_domain }}"
        backup_user_name:    "backuper-{{ db_instance_name }}-{{ zone }}"
        admin_password:      "{{ lookup('password', credentials_store + '/psql/' + cred_zone + '/' + db_instance_name + '/admin_password chars=ascii_letters,digits') }}"
        replicator_password: "{{ lookup('password', credentials_store + '/psql/' + cred_zone + '/' + db_instance_name + '/replicator_password chars=ascii_letters,digits') }}"
    - debug: var=hostvars[inventory_hostname]

- name: Set up backup bucket
  hosts: aws_commands_host
  gather_facts: false
  become: false
  # assumes AWS_ACCESS_KEY_ID, AWS_SECRET_SECRET_KEY are set to the values of `backup_configurer` user
  # which gives permission to create buckets and users
  tasks:
    - name: Create backup aws user
      iam:
        iam_type: user
        name: "{{ backup_user_name }}"
        state: present
        access_key_state: create
      register: created_user # need this name for the template

    - debug:
        msg: "{{ backup_user_name | iam_user_arn() }}"

    - debug:
        msg: "{{ created_user }}"

    - name: Create AWS access file
      template:
        src: "aws_user.credentials.sh.j2"
        dest: "{{ credentials_store }}/backup/{{ backup_user_name }}.credentials.sh"
      when: "'user_meta' in created_user"
      register: credentials_sh_file

    # TODO wait for user to have been created (eventual consistency)
    # Otherwise getting:
    #   "Invalid principal in policy"
    - debug:
        msg: "{{ lookup('template', 'backup_bucket_policy.json.j2') }}"
        verbosity: 3

    - name: Wait for backup user created and available
      shell: sleep 7 # unfortunately there is no iam_facts module available,
        # which we could use to check/wait for user;
        # another possibility: `aws iam get-user --user-name ...` in a loop

    - name: Create backup bucket
      s3_bucket:
        name: "{{ backup_bucket_name }}"
        policy: "{{ lookup('template', 'backup_bucket_policy.json.j2') }}"
        versioning: false # no trash bin needed
      register: backup_bucket

    - debug: var=backup_bucket

    - name: Set retention for backups
      s3_lifecycle:
        name: "{{ backup_bucket_name }}"
        rule_id: clean_old_backups
        expiration_days: 30

    # TODO implement "Permanently delete previous versions" a new ansible module, use boto3


- name: Register postgres master
  hosts: postgres-MASTER
  gather_facts: False
  remote_user: root
  become_user: root
  become: true
  tasks:
    - name: Check current service's dns setting
      shell: dig +short CNAME {{ postgres_service_domain }}
      changed_when: false
      register: previous_master_host

    - name: Register the host under service's name
      shell: "set-dns CNAME {{ postgres_service_domain }}  {{ inventory_hostname }}"
      when: "previous_master_host.stdout != inventory_hostname + '.'"
      become: false
      delegate_to: localhost

    - name: Ensure postgres master is started
      service: name=postgresql enabled=yes state=started

- name: Configure postgres slaves
  hosts: postgres-SLAVES
  remote_user: root
  tasks:
    - name: Check existing configuration file
      stat: path=/var/local/postgresql/data/postgresql.conf
      register: configuration_file

    - name: Set up replicator credentials
      template:
        src: "replicator-pgpass.conf.j2"
        dest: "/var/local/postgresql/replicator-pgpass.conf"
        owner: postgres
        mode: 0600
      notify: Restart postgres

    - name: Run backup (initial replication) from master, only for empty slaves
      # Note: you can remove `--checkpoint=fast` from the following pg_basebackup
      # call to reduce (spread) load on master during replication.
      # Replication will take longer then.
      #
      # Possible extension: use --max-rate to throttle replication, e.g. `--max-rate 20000` for 20 MB/s
      shell: PGPASSFILE=/var/local/postgresql/replicator-pgpass.conf pg_basebackup -D /var/local/postgresql/data/ -h {{ slave_upstream }} -U replicator --progress -R -w --xlog-method=stream --checkpoint=fast
      become_user: postgres
      become: true
      when: not configuration_file.stat.exists

    - name: Check if replication is configured
      stat: path=/var/local/postgresql/data/recovery.conf
      register: recovery_configuration_file

    - name: Start postgres on the slave for continuous replication
      service: name=postgresql enabled=yes state=started
      when: recovery_configuration_file.stat.exists

    - name: Do not run full backup on slave
      cron:
        name: postgres full backup
        user: postgres
        state: absent

    - debug:
        msg: |
          Please remember to set up monitoring for the new cluster - is currently a separate step!

          You can now use the postgres instance with

          psql -h {{ postgres_service_domain }} -U admin -d postgres

          The password, initially set by this ansible playbook is
          {{ admin_password }}
          Please change on first usage!
          Please create additional users with less privileges to use with you application!

  handlers:
    - name: Restart postgres
      service: name=postgresql enabled=yes state=restarted


